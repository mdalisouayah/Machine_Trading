{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "library to scrape sec edgar website\n",
    "https://github.com/coyo8/sec-edgar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import regex as re\n",
    "import datetime\n",
    "#import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and modules\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster\n",
    "#['aapl' 'amzn' 'csco' 'ebay' 'fcbk' 'msft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl=pd.read_csv('../csv/aapl_8.csv', index_col=0)\n",
    "#goog=pd.read_csv('../csv/goog_8.csv', index_col=0)\n",
    "msft=pd.read_csv('../csv/msft_8.csv', index_col=0)\n",
    "#adbe=pd.read_csv('../csv/adbe_8.csv', index_col=0)\n",
    "#akam=pd.read_csv('../csv/akam_8.csv', index_col=0)\n",
    "fcbk=pd.read_csv('../csv/fcbk_8.csv', index_col=0)\n",
    "amzn=pd.read_csv('../csv/amzn_8.csv', index_col=0)\n",
    "#ibm=pd.read_csv('../csv/ibm_8.csv', index_col=0)\n",
    "#intc=pd.read_csv('../csv/intc_8.csv', index_col=0)\n",
    "csco=pd.read_csv('../csv/csco_8.csv', index_col=0)\n",
    "#ea=pd.read_csv('../csv/ea_8.csv', index_col=0)\n",
    "ebay=pd.read_csv('../csv/ebay_8.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = aapl\n",
    "#comps = aapl.append(goog, ignore_index=True, sort=None)\n",
    "comps = comps.append(msft, ignore_index=True, sort=None)\n",
    "#comps = comps.append(adbe, ignore_index=True, sort=None)\n",
    "#comps = comps.append(akam, ignore_index=True, sort=None)\n",
    "comps = comps.append(fcbk, ignore_index=True, sort=None)\n",
    "comps = comps.append(amzn, ignore_index=True, sort=None)\n",
    "#comps = comps.append(ibm, ignore_index=True, sort=None)\n",
    "#comps = comps.append(intc, ignore_index=True, sort=None)\n",
    "comps = comps.append(csco, ignore_index=True, sort=None)\n",
    "#comps = comps.append(ea, ignore_index=True, sort=None)\n",
    "comps = comps.append(ebay, ignore_index=True, sort=None)\n",
    "comps.to_csv('../csv/stocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>neg_text</th>\n",
       "      <th>uncert_text</th>\n",
       "      <th>pos_text</th>\n",
       "      <th>delta_0_p</th>\n",
       "      <th>delta_1_p</th>\n",
       "      <th>delta_1_0</th>\n",
       "      <th>delta_3_np</th>\n",
       "      <th>delta_7_np</th>\n",
       "      <th>delta_3_n0</th>\n",
       "      <th>delta_7_n0</th>\n",
       "      <th>period</th>\n",
       "      <th>an_buy</th>\n",
       "      <th>an_hold</th>\n",
       "      <th>an_sell</th>\n",
       "      <th>an_rating</th>\n",
       "      <th>an_d_p</th>\n",
       "      <th>an_d_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2009-04-17</td>\n",
       "      <td>amzn</td>\n",
       "      <td>against break challenge challenges closure con...</td>\n",
       "      <td>appear believe could differ may might pending ...</td>\n",
       "      <td>able achieving advantage advantages benefit be...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date ticker                                           neg_text  \\\n",
       "253  2009-04-17   amzn  against break challenge challenges closure con...   \n",
       "\n",
       "                                           uncert_text  \\\n",
       "253  appear believe could differ may might pending ...   \n",
       "\n",
       "                                              pos_text  delta_0_p  delta_1_p  \\\n",
       "253  able achieving advantage advantages benefit be...          1          1   \n",
       "\n",
       "     delta_1_0  delta_3_np  delta_7_np  delta_3_n0  delta_7_n0  period  \\\n",
       "253          0           0           0           1           0     6.0   \n",
       "\n",
       "     an_buy  an_hold  an_sell  an_rating  an_d_p  an_d_0  \n",
       "253     9.0     20.0      3.0      3.406       1       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by date so that companies are shuffled (test not based on few companies not in train)\n",
    "comps.sort_values(by=['date'],inplace=True)\n",
    "comps.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amzn', 'ebay', 'aapl', 'msft', 'fcbk', 'csco'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps.ticker.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "tickers = comps.ticker\n",
    "ticker_encoder = LabelEncoder()\n",
    "ticker_encoded = ticker_encoder.fit_transform(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps['ticker'] = ticker_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set text feature and target\n",
    "X = comps['neg_text'] #alternatively: pos_text uncert_text\n",
    "y = comps['delta_7_np']\n",
    "#y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_test_split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42,\n",
    "                                                    shuffle=False\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((419,), (419,), (105,), (105,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifers and Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer initialized (also see GS 506)\n",
    "cvec = CountVectorizer()\n",
    "tf = TfidfVectorizer()\n",
    "svc = svm.SVC()\n",
    "nb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countVectorizer and Multinomial Naive Bayes are instantiated\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vec', tf),\n",
    "    ('clf', svc),\n",
    "    #('ss', StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5727923627684964,\n",
       " {'clf__C': 7,\n",
       "  'clf__gamma': 0.003,\n",
       "  'vec__max_features': 400,\n",
       "  'vec__min_df': 0,\n",
       "  'vec__ngram_range': (1, 1),\n",
       "  'vec__norm': 'l2',\n",
       "  'vec__use_idf': True})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best of TFIDF: \n",
    "pipe_params = {\n",
    "    'vec__max_features' : [400],\n",
    "    'clf__C': [7],\n",
    "    'clf__gamma':[0.003],\n",
    "    'vec__use_idf' : [True],\n",
    "    'vec__norm':['l2'],\n",
    "    'vec__min_df' : [0],\n",
    "    'vec__ngram_range':[(1,1)],\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid= pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5727923627684964,\n",
       " {'clf__C': 7,\n",
       "  'clf__gamma': 0.003,\n",
       "  'vec__binary': True,\n",
       "  'vec__max_df': 100,\n",
       "  'vec__max_features': 520,\n",
       "  'vec__min_df': 3,\n",
       "  'vec__ngram_range': (1, 3)})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best of CVEC: \n",
    "pipe_params = {\n",
    "    'vec__max_features' : [520],\n",
    "    'clf__C': [7],\n",
    "    'clf__gamma':[0.003],\n",
    "    'vec__min_df' : [3],\n",
    "    'vec__max_df':[100],\n",
    "    'vec__ngram_range':[(1,3)],\n",
    "    'vec__binary':[True]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid= pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.97"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(max(comps['delta_7_np'].value_counts(normalize=True)*100),2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
